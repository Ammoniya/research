#!/usr/bin/env python3
"""
WordPress Vulnerability Clone Mining - Phase 2

This script implements historical clone detection and temporal analysis of
vulnerability patterns across the WordPress plugin ecosystem.

Usage:
    python mine_vulnerability_clones.py [--max-plugins N] [--max-revisions M]
"""

import argparse
import json
import os
import sys
from datetime import datetime
from typing import List, Dict

from vulnerability_miner import (
    MinerConfig,
    HistoricalScanner,
    PatternMatcher,
    TemporalTracker,
    MetricsCalculator,
    ZeroDayDetector,
    PluginTimeline,
    VulnerabilityClone,
    FixStatus,
    ProcessingStats
)


class VulnerabilityCloneMiner:
    """Main orchestrator for vulnerability clone mining."""

    def __init__(self, config: MinerConfig):
        """
        Initialize miner.

        Args:
            config: Miner configuration
        """
        self.config = config
        self.scanner = HistoricalScanner(
            config.svn_repos_dir,
            config.cache_dir if config.cache_plugin_histories else None,
            config.svn_log_timeout,
            config.svn_cat_timeout,
            config.svn_list_timeout
        )
        self.pattern_matcher = PatternMatcher(config.min_pattern_confidence)
        self.temporal_tracker = TemporalTracker(config.timelines_dir)
        self.metrics_calculator = MetricsCalculator(config.metrics_dir)
        self.zero_day_detector = ZeroDayDetector(
            config.zero_day_confidence_threshold,
            config.zero_days_dir
        ) if config.enable_zero_day_detection else None

        self.stats = ProcessingStats()
        self.progress_data = self._load_progress()

    def _load_progress(self) -> Dict:
        """Load progress from file."""
        if os.path.exists(self.config.progress_file):
            with open(self.config.progress_file, 'r') as f:
                return json.load(f)
        return {'processed_plugins': [], 'processed_signatures': []}

    def _save_progress(self):
        """Save progress to file."""
        os.makedirs(os.path.dirname(self.config.progress_file), exist_ok=True)
        with open(self.config.progress_file, 'w') as f:
            json.dump(self.progress_data, f, indent=2)

    def mine_all_vulnerabilities(self):
        """Mine all vulnerability patterns across plugin ecosystem."""
        print("=" * 80)
        print("WORDPRESS VULNERABILITY CLONE MINING - PHASE 2")
        print("=" * 80)
        print()

        # Show scan mode
        scan_mode_desc = "all commits" if self.config.scan_mode == 'commits' else "tagged releases only"
        print(f"Scan mode: {self.config.scan_mode.upper()} ({scan_mode_desc})")
        print()

        # Load signatures
        print("Loading vulnerability signatures...")
        signatures = self.pattern_matcher.load_signatures(self.config.signatures_dir)
        self.stats.total_signatures_searched = len(signatures)
        print(f"Loaded {len(signatures)} vulnerability signatures")
        print()

        # Get plugin list
        plugins = self.config.get_plugin_list()
        self.stats.total_plugins = len(plugins)
        print(f"Scanning {len(plugins)} plugins")
        print()

        # Start mining
        self.stats.start_time = datetime.now()

        all_clones = []

        # Process each signature
        for sig_idx, signature in enumerate(signatures, 1):
            print(f"\n[{sig_idx}/{len(signatures)}] Processing signature: {signature.signature_id}")
            print(f"  Type: {signature.vuln_type}")
            print(f"  Pattern: {signature.pattern_string}")

            # Skip if already processed
            if signature.signature_id in self.progress_data.get('processed_signatures', []):
                print("  [SKIP] Already processed")
                continue

            # Mine this signature across all plugins
            clone = self.mine_signature_across_plugins(signature, plugins)

            if clone and clone.total_clones > 0:
                all_clones.append(clone)
                self.temporal_tracker.save_vulnerability_clone(clone)

                # Calculate and save metrics
                metrics = self.metrics_calculator.calculate_all_metrics(
                    signature.signature_id,
                    signature.vuln_type,
                    len(plugins),
                    clone.timelines
                )
                self.metrics_calculator.save_metrics(metrics)

                print(f"  [FOUND] {clone.total_clones} clones across {len(clone.affected_plugins)} plugins")
                print(f"  VPP: {metrics.vpp:.2f}%, PPD: {metrics.ppd:.0f} days, SFR: {metrics.sfr:.0f}%")

            # Mark signature as processed
            if 'processed_signatures' not in self.progress_data:
                self.progress_data['processed_signatures'] = []
            self.progress_data['processed_signatures'].append(signature.signature_id)

            # Save progress periodically
            if sig_idx % self.config.save_frequency == 0:
                self._save_progress()

        # Final save
        self._save_progress()

        # Generate ecosystem metrics
        print("\n" + "=" * 80)
        print("Generating ecosystem metrics...")
        ecosystem_metrics = self.metrics_calculator.calculate_ecosystem_metrics(
            all_clones,
            len(plugins)
        )
        self.metrics_calculator.save_ecosystem_metrics(ecosystem_metrics)

        # Generate report
        report = self.metrics_calculator.generate_metrics_report(all_clones, len(plugins))
        report_path = os.path.join(self.config.metrics_dir, "research_report.txt")
        with open(report_path, 'w') as f:
            f.write(report)

        print(report)

        # Stats
        self.stats.end_time = datetime.now()
        self.stats.calculate_elapsed()

        print("\n" + "=" * 80)
        print("MINING COMPLETE")
        print("=" * 80)
        print(f"Total signatures searched: {self.stats.total_signatures_searched}")
        print(f"Total plugins scanned:     {self.stats.plugins_processed}")
        print(f"Total matches found:       {self.stats.total_matches_found}")
        print(f"Total zero-days found:     {self.stats.total_zero_days_found}")
        print(f"Elapsed time:              {self.stats.elapsed_seconds:.0f}s")
        print()

    def mine_signature_across_plugins(
        self,
        signature,
        plugins: List[str]
    ) -> VulnerabilityClone:
        """
        Mine a single signature across all plugins.

        Args:
            signature: Signature pattern
            plugins: List of plugin slugs

        Returns:
            VulnerabilityClone: Clone data
        """
        timelines = []
        zero_day_findings = []

        print(f"  Scanning {len(plugins)} plugins for this signature...")
        for idx, plugin_slug in enumerate(plugins, 1):
            # Skip if already processed
            plugin_sig_key = f"{plugin_slug}:{signature.signature_id}"
            if plugin_sig_key in self.progress_data.get('processed_plugins', []):
                continue

            # Show progress
            if idx % 10 == 0 or idx == 1:
                print(f"    [{idx}/{len(plugins)}] Scanning plugin: {plugin_slug}")
                sys.stdout.flush()

            # Mine this plugin
            timeline = self.mine_plugin_for_signature(plugin_slug, signature)

            if timeline and timeline.total_revisions_with_pattern > 0:
                timelines.append(timeline)
                self.temporal_tracker.save_timeline(timeline)

                # Check for zero-day in current version
                if self.zero_day_detector and timeline.currently_vulnerable:
                    # This would require checking current version code
                    # Simplified here
                    pass

            # Mark as processed
            if 'processed_plugins' not in self.progress_data:
                self.progress_data['processed_plugins'] = []
            self.progress_data['processed_plugins'].append(plugin_sig_key)

            self.stats.plugins_processed += 1

        # Build vulnerability clone
        clone = self.temporal_tracker.build_vulnerability_clone(
            signature_id=signature.signature_id,
            original_cve=signature.signature_id if signature.signature_id.startswith('CVE-') else None,
            original_plugin="",  # Would need to track this
            vulnerability_type=signature.vuln_type,
            pattern=signature.pattern_string,
            timelines=timelines
        )

        return clone

    def mine_plugin_for_signature(
        self,
        plugin_slug: str,
        signature
    ) -> PluginTimeline:
        """
        Mine a single plugin for a signature pattern.

        Args:
            plugin_slug: Plugin slug
            signature: Signature pattern

        Returns:
            PluginTimeline: Timeline for this plugin
        """
        # Get plugin path
        plugin_path = self.scanner.get_plugin_path(plugin_slug)
        if not plugin_path:
            return None

        # Get revisions based on scan mode
        if self.config.scan_mode == 'releases':
            revisions = self.scanner.get_release_revisions(
                plugin_slug,
                self.config.max_revisions_per_plugin
            )
        else:  # commits mode
            revisions = self.scanner.get_all_revisions(
                plugin_slug,
                self.config.max_revisions_per_plugin
            )

        if not revisions:
            return None

        # Scan each revision for pattern
        all_matches = []

        if len(revisions) > 10:
            revision_type = "releases" if self.config.scan_mode == 'releases' else "revisions"
            print(f"      Scanning {len(revisions)} {revision_type} for {plugin_slug}...")
            sys.stdout.flush()

        for rev_idx, rev_info in enumerate(revisions, 1):
            revision = rev_info['revision']

            # Show progress for each revision
            print(f"        [{rev_idx}/{len(revisions)}] Revision {revision}... ", end='', flush=True)

            # Get PHP files at this revision
            php_files = self.scanner.get_all_php_files_at_revision(plugin_slug, revision)
            print(f"({len(php_files)} PHP files)", flush=True)

            files_to_scan = php_files[:10]  # Limit files per revision for performance
            for file_idx, file_path in enumerate(files_to_scan, 1):
                # Show progress for file scanning
                if len(files_to_scan) > 3:
                    print(f"          [{file_idx}/{len(files_to_scan)}] {file_path[:50]}...", end='\r', flush=True)

                # Get file content
                content = self.scanner.get_file_content_at_revision(
                    plugin_slug,
                    file_path,
                    revision
                )

                if not content:
                    continue

                # Find pattern matches
                matches = self.pattern_matcher.find_pattern_in_code(
                    content,
                    signature,
                    file_path
                )

                if matches:
                    print(f"\n          MATCH in {file_path}!", flush=True)
                    for match in matches:
                        match['revision'] = revision
                        match['revision_date'] = rev_info['date']
                        all_matches.append(match)

            # Clear the file progress line if we showed it
            if len(files_to_scan) > 3:
                print(" " * 80, end='\r', flush=True)

        # Build timeline
        timeline = self.temporal_tracker.build_timeline(
            plugin_slug,
            signature.signature_id,
            signature.pattern_string,
            all_matches
        )

        # Determine fix status
        current_version = self.scanner.get_current_version(plugin_slug)
        # Simplified: assume if no recent matches, it's fixed
        currently_vulnerable = False
        if all_matches and revisions:
            latest_match_rev = max(m['revision'] for m in all_matches)
            latest_rev = revisions[0]['revision']
            currently_vulnerable = (latest_rev - latest_match_rev) < 10

        timeline.currently_vulnerable = currently_vulnerable
        timeline.fix_status = self.temporal_tracker.determine_fix_status(
            timeline,
            [],  # Would need actual CVE list
            currently_vulnerable
        )

        if all_matches:
            self.stats.total_matches_found += len(all_matches)

        return timeline


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Mine WordPress vulnerability clones across plugin ecosystem'
    )
    parser.add_argument(
        '--max-plugins',
        type=int,
        help='Maximum number of plugins to scan'
    )
    parser.add_argument(
        '--max-revisions',
        type=int,
        help='Maximum revisions per plugin to scan'
    )
    parser.add_argument(
        '--scan-mode',
        choices=['commits', 'releases'],
        default='commits',
        help='Scan mode: "commits" scans all SVN commits (slow but comprehensive), '
             '"releases" scans only tagged releases (fast, official versions only)'
    )
    parser.add_argument(
        '--signatures-dir',
        default='signatures',
        help='Directory containing vulnerability signatures'
    )
    parser.add_argument(
        '--output-dir',
        default='mining_results',
        help='Output directory for mining results'
    )

    args = parser.parse_args()

    # Create configuration
    config = MinerConfig(
        signatures_dir=args.signatures_dir,
        mining_output_dir=args.output_dir,
        max_plugins_to_scan=args.max_plugins,
        max_revisions_per_plugin=args.max_revisions,
        scan_mode=args.scan_mode
    )

    try:
        config.validate()
        config.ensure_directories()
    except ValueError as e:
        print(f"Configuration error: {e}")
        sys.exit(1)

    # Run miner
    miner = VulnerabilityCloneMiner(config)
    miner.mine_all_vulnerabilities()


if __name__ == '__main__':
    main()
