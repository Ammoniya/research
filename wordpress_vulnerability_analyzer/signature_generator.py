"""Main signature generation orchestrator."""

import json
from typing import List, Optional
from datetime import datetime
from collections import defaultdict
from pathlib import Path

from .models import VulnerabilityInfo, CodeSignature, ProcessingStats
from .svn_extractor import SVNDiffExtractor
from .progress_manager import ProgressManager, SignatureStorage
from .config import Config
from .ast_parser import PHPASTParser
from .unified_diff_parser import UnifiedDiffParser
from .ast_line_mapper import ASTLineMapper
from .ast_normalizer import ASTNormalizer


class SignatureGenerator:
    """Orchestrates simple diff extraction from vulnerabilities."""

    def __init__(self, config: Config):
        """
        Initialize signature generator.

        Args:
            config: Configuration object
        """
        self.config = config
        self.svn_extractor = SVNDiffExtractor(
            config.svn_repos_dir,
            config.diff_timeout
        )
        self.progress_manager = ProgressManager(config.progress_file)
        self.signature_storage = SignatureStorage(config.signatures_output_dir)

        # AST components
        self.ast_parser = PHPASTParser()
        self.diff_parser = UnifiedDiffParser()
        self.line_mapper = ASTLineMapper()
        self.normalizer = ASTNormalizer(
            normalize_vars=True,
            normalize_strings=False,
            normalize_function_names=False
        )

    def generate_signature(
        self,
        vuln_info: VulnerabilityInfo,
        diff_content: str,
        vuln_version: str,
        fixed_version: str
    ) -> Optional[CodeSignature]:
        """
        Generate simplified signature from vulnerability and diff.

        Args:
            vuln_info: Vulnerability information
            diff_content: Diff content string
            vuln_version: Vulnerable version tag
            fixed_version: Fixed version tag

        Returns:
            Optional[CodeSignature]: Generated signature or None
        """
        if not diff_content:
            return None

        # Parse diff into blocks to extract pre/post code
        diff_blocks = self.svn_extractor.parse_diff_to_blocks(diff_content)

        if not diff_blocks:
            return None

        # Get diff statistics
        diff_stats = self.svn_extractor.get_diff_stats(diff_blocks)

        # Extract pre-patch and post-patch code
        pre_patch_code = self._extract_code(diff_blocks, 'before')
        post_patch_code = self._extract_code(diff_blocks, 'after')

        # Create simplified signature
        signature = CodeSignature(
            cve=vuln_info.cve,
            plugin_slug=vuln_info.plugin_slug,
            vuln_type=vuln_info.vuln_type,
            title=vuln_info.title,
            wordfence_uuid=vuln_info.wordfence_uuid,
            vulnerable_version=vuln_version,
            patched_version=fixed_version,
            affected_versions=vuln_info.affected_versions,
            patch_location=f"{vuln_version} -> {fixed_version}",
            pre_patch_code=pre_patch_code,
            post_patch_code=post_patch_code,
            unified_diff=diff_content,
            files_changed=diff_stats['file_changes'],
            lines_added=diff_stats['total_lines_added'],
            lines_removed=diff_stats['total_lines_removed'],
            references=vuln_info.references,
        )

        return signature

    def generate_ast_signatures_from_files(
        self,
        plugin_slug: str,
        vuln_version: str,
        fixed_version: str,
        diff_content: str
    ) -> List[dict]:
        """
        Generate AST signatures by reading actual files from SVN repository.

        This is the improved approach that:
        1. Parses unified diff to get file paths and changed line ranges
        2. Reads actual vulnerable/patched files from SVN repo
        3. Parses complete files into ASTs
        4. Maps line ranges to find exact changed nodes
        5. Normalizes patterns for reusability

        Args:
            plugin_slug: Plugin identifier
            vuln_version: Vulnerable version tag
            fixed_version: Fixed version tag
            diff_content: Unified diff string

        Returns:
            List of AST signature dictionaries
        """
        ast_signatures = []

        # Parse unified diff to get file paths and line ranges
        file_diffs = self.diff_parser.parse(diff_content)
        php_files = self.diff_parser.extract_php_files(file_diffs)

        for file_diff in php_files:
            # Extract filename from diff paths (remove a/ b/ prefix)
            file_path = file_diff.new_path
            if file_path.startswith('b/'):
                file_path = file_path[2:]
            elif file_path.startswith('a/'):
                file_path = file_path[2:]

            # Construct paths to actual files in SVN repository
            vuln_file_path = Path(self.config.svn_repos_dir) / plugin_slug / 'tags' / vuln_version / file_path
            fixed_file_path = Path(self.config.svn_repos_dir) / plugin_slug / 'tags' / fixed_version / file_path

            # Check if files exist
            if not vuln_file_path.exists():
                print(f"      [!] Vulnerable file not found: {vuln_file_path}")
                continue

            if not fixed_file_path.exists():
                print(f"      [!] Fixed file not found: {fixed_file_path}")
                continue

            # Read actual files
            try:
                with open(vuln_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    vuln_code = f.read()

                with open(fixed_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    fixed_code = f.read()
            except Exception as e:
                print(f"      [!] Error reading files: {e}")
                continue

            # Parse into ASTs
            vuln_ast = self.ast_parser.parse(vuln_code)
            fixed_ast = self.ast_parser.parse(fixed_code)

            if not vuln_ast or not fixed_ast:
                print(f"      [!] Failed to parse ASTs for {file_path}")
                continue

            # Get changed line ranges from the diff
            vuln_ranges = self.diff_parser.get_changed_line_ranges_unified(file_diff.hunks, version='old')
            fixed_ranges = self.diff_parser.get_changed_line_ranges_unified(file_diff.hunks, version='new')

            if not vuln_ranges:
                continue

            # Find nodes in changed ranges
            vuln_nodes = []
            for start, end in vuln_ranges:
                vuln_nodes.extend(self.line_mapper.find_nodes_in_range(vuln_ast, start, end))

            fixed_nodes = []
            for start, end in fixed_ranges:
                fixed_nodes.extend(self.line_mapper.find_nodes_in_range(fixed_ast, start, end))

            if not vuln_nodes:
                continue

            # Filter to meaningful nodes
            meaningful_vuln = self._filter_to_meaningful_nodes(vuln_nodes)
            meaningful_fixed = self._filter_to_meaningful_nodes(fixed_nodes)

            if not meaningful_vuln:
                meaningful_vuln = vuln_nodes

            # Find smallest differing pair
            vuln_node, fixed_node = self._find_smallest_differing_pair(
                meaningful_vuln,
                meaningful_fixed if meaningful_fixed else fixed_nodes
            )

            if not vuln_node:
                continue

            # Normalize patterns
            pattern_sig = self.normalizer.create_pattern_signature(vuln_node, fixed_node)
            security_diff = self.normalizer.compare_security_functions(vuln_node, fixed_node)

            # Calculate signature quality score
            score_result = self._score_signature_quality(
                vuln_node, fixed_node, security_diff, pattern_sig['pattern_type']
            )

            # Skip noise (whitespace-only, formatting, etc.)
            if score_result['is_noise']:
                continue

            # Create AST signature
            ast_sig = {
                'file_path': file_path,
                'vulnerable_pattern': pattern_sig['vulnerable_pattern'],
                'patched_pattern': pattern_sig.get('patched_pattern'),
                'pattern_type': pattern_sig['pattern_type'],
                'security_functions_added': list(security_diff['added']),
                'security_functions_removed': list(security_diff['removed']),
                'vulnerable_code_snippet': vuln_node.text[:500] if vuln_node.text else '',
                'patched_code_snippet': fixed_node.text[:500] if fixed_node and fixed_node.text else '',
                'confidence_score': score_result['score'],
                'is_high_confidence': score_result['is_high_confidence'],
                'score_breakdown': score_result['breakdown'],
                'constraints': {
                    'file_extension': Path(file_path).suffix,
                    'node_type': vuln_node.node_type,
                    'changed_lines': vuln_ranges,
                }
            }

            ast_signatures.append(ast_sig)

        return ast_signatures

    def _filter_to_meaningful_nodes(self, nodes: List) -> List:
        """Filter nodes to statement/expression level."""
        meaningful_types = {
            'expression_statement', 'echo_statement', 'return_statement',
            'if_statement', 'while_statement', 'for_statement', 'foreach_statement',
            'assignment_expression', 'function_call_expression',
            'binary_expression', 'concatenation', 'string_concatenation',
            'member_call_expression', 'scoped_call_expression',
            'function_call', 'method_call', 'scoped_call',
            'function_definition', 'method_declaration', 'class_declaration',
        }

        exclude_types = {'echo', 'if', 'return', 'for', 'while', '(', ')', '{', '}', ';', ',', '.', '+', '-', '*', '/', "'", '"'}

        meaningful = []
        for node in nodes:
            if node.node_type in exclude_types:
                continue
            if node.node_type in meaningful_types:
                meaningful.append(node)
            elif node.text and len(node.text) > 10 and any(func in node.text.lower() for func in ['esc_', 'sanitize_', 'wp_kses', 'prepare', '$_']):
                meaningful.append(node)

        return meaningful

    def _find_smallest_differing_pair(self, vuln_nodes: List, fixed_nodes: List):
        """Find smallest pair of nodes that differ."""
        if not vuln_nodes or not fixed_nodes:
            return (None, None)

        # Find smallest vulnerable node
        smallest_vuln = min(vuln_nodes, key=lambda n: n.end_byte - n.start_byte)

        # Find corresponding fixed node
        best_fixed = None
        best_score = float('inf')

        vuln_line = smallest_vuln.start_point[0]

        for fixed_node in fixed_nodes:
            line_dist = abs(fixed_node.start_point[0] - vuln_line)
            type_match = 0 if fixed_node.node_type == smallest_vuln.node_type else 10
            score = line_dist + type_match

            if score < best_score:
                best_score = score
                best_fixed = fixed_node

        if best_fixed:
            return (smallest_vuln, best_fixed)

        return (smallest_vuln, fixed_nodes[0] if fixed_nodes else None)

    def _score_signature_quality(self, vuln_node, fixed_node, security_diff: dict, pattern_type: str) -> dict:
        """
        Score signature quality to filter signal from noise.

        Args:
            vuln_node: Vulnerable AST node
            fixed_node: Fixed AST node
            security_diff: Security functions diff
            pattern_type: Pattern type detected

        Returns:
            dict with keys: score, is_high_confidence, is_noise, breakdown
        """
        score = 0
        breakdown = {}

        vuln_text = vuln_node.text.strip() if vuln_node.text else ''
        fixed_text = fixed_node.text.strip() if fixed_node and fixed_node.text else ''

        # Check 1: Whitespace-only change (NOISE)
        vuln_normalized = ' '.join(vuln_text.split())
        fixed_normalized = ' '.join(fixed_text.split())

        if vuln_normalized == fixed_normalized:
            return {
                'score': 0,
                'is_high_confidence': False,
                'is_noise': True,
                'breakdown': {'reason': 'whitespace_only_change'}
            }

        # Check 2: Security functions added (STRONG SIGNAL)
        if security_diff['added']:
            score += 50
            breakdown['security_functions_added'] = list(security_diff['added'])

            # Extra points for critical security functions
            critical_funcs = {
                # CSRF/Nonce Protection (highest priority)
                'wp_verify_nonce', 'check_admin_referer', 'check_ajax_referer',
                'wp_create_nonce', 'wp_nonce_field', 'wp_nonce_url',

                # Authorization/Capability Checks (highest priority)
                'current_user_can', 'current_user_can_for_blog', 'user_can',
                'is_super_admin', 'map_meta_cap',

                # SQL Security (critical)
                'prepare', 'esc_sql', 'esc_like', 'absint', 'intval',

                # Input Sanitization (high priority)
                'sanitize_text_field', 'sanitize_email', 'sanitize_file_name',
                'sanitize_key', 'sanitize_title', 'sanitize_title_with_dashes',
                'sanitize_user', 'sanitize_option', 'sanitize_mime_type',
                'sanitize_textarea_field', 'sanitize_hex_color', 'sanitize_hex_color_no_hash',
                'wp_kses', 'wp_kses_post', 'wp_kses_data', 'wp_kses_allowed_html',

                # Output Escaping (XSS prevention)
                'esc_html', 'esc_attr', 'esc_url', 'esc_js', 'esc_textarea', 'esc_xml',

                # File Security
                'wp_check_filetype', 'wp_check_filetype_and_ext', 'validate_file',
                'wp_handle_upload', 'wp_upload_bits', 'wp_get_mime_types',

                # URL/Path Validation
                'wp_safe_redirect', 'wp_sanitize_redirect', 'wp_validate_redirect',
                'wp_http_validate_url', 'esc_url_raw',

                # Data Validation
                'is_email', 'rest_sanitize_boolean', 'rest_validate_request_arg',
                'wp_validate_boolean', 'validate_username',

                # Additional Security Functions
                'wp_unslash', 'stripslashes_deep', 'wp_strip_all_tags',
                'remove_accents', 'seems_utf8',
            }

            if any(func in security_diff['added'] for func in critical_funcs):
                score += 30
                breakdown['critical_security_function'] = True

        # Check 3: Security functions removed (ANTI-PATTERN - possible noise or refactor)
        if security_diff['removed']:
            score -= 40
            breakdown['security_functions_removed'] = list(security_diff['removed'])

            # If ONLY removing security functions with nothing added, it's likely noise/refactor
            if security_diff['removed'] and not security_diff['added']:
                breakdown['likely_refactor'] = True

        # Check 4: Pattern type indicates security fix
        security_patterns = {
            'missing_output_escaping': 30,
            'missing_input_sanitization': 30,
            'sql_injection': 40,
            'missing_nonce_verification': 50,  # CSRF is critical
            'missing_capability_check': 35,
            'unsafe_deserialization': 40
        }

        if pattern_type in security_patterns:
            points = security_patterns[pattern_type]
            score += points
            breakdown['security_pattern'] = pattern_type
            breakdown['pattern_points'] = points

        # Check 5: Identical function calls (likely just formatting)
        # Example: esc_attr($x) -> esc_attr($x) with different whitespace
        if vuln_normalized == fixed_normalized:
            score -= 30
            breakdown['identical_normalized'] = True

        # Check 6: Structural change vs superficial
        vuln_structure = self._get_node_structure(vuln_node)
        fixed_structure = self._get_node_structure(fixed_node)

        if vuln_structure != fixed_structure:
            score += 20
            breakdown['structural_change'] = True
        else:
            breakdown['superficial_change'] = True

        # Determine confidence and noise flags
        is_high_confidence = score >= 70
        is_noise = score < 10

        return {
            'score': max(0, score),  # Don't go negative
            'is_high_confidence': is_high_confidence,
            'is_noise': is_noise,
            'breakdown': breakdown
        }

    def _get_node_structure(self, node) -> str:
        """Get simplified structure signature of a node."""
        if not node or not hasattr(node, 'node_type'):
            return ''

        if not node.children:
            return node.node_type

        child_types = [self._get_node_structure(c) for c in node.children[:5]]  # Limit depth
        return f"{node.node_type}({','.join(child_types)})"

    def _extract_code(self, diff_blocks: List, code_type: str) -> str:
        """
        Extract code from diff blocks.

        Args:
            diff_blocks: List of DiffBlock objects
            code_type: 'before' or 'after'

        Returns:
            str: Concatenated code from all blocks
        """
        snippets = []
        for block in diff_blocks:
            if code_type == 'before' and block.before_code:
                snippets.append(f"=== File: {block.file_path} ===\n{block.before_code}")
            elif code_type == 'after' and block.after_code:
                snippets.append(f"=== File: {block.file_path} ===\n{block.after_code}")

        return '\n\n'.join(snippets)

    def save_consolidated_signatures(self, output_file: str):
        """
        Save all signatures to consolidated JSON file.

        Args:
            output_file: Path to output file
        """
        signatures = self.signature_storage.load_all_signatures()

        with open(output_file, 'w') as f:
            json.dump({
                'metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'total_signatures': len(signatures),
                    'version': '3.0.0-simplified'
                },
                'signatures': signatures
            }, f, indent=2)

    def generate_statistics(self) -> dict:
        """
        Generate statistics from all signatures.

        Returns:
            dict: Statistics dictionary
        """
        signatures = self.signature_storage.load_all_signatures()

        vuln_type_counts = defaultdict(int)
        total_files_changed = 0
        total_lines_added = 0
        total_lines_removed = 0

        for sig in signatures:
            vuln_type_counts[sig['vuln_type']] += 1
            total_files_changed += sig.get('files_changed', 0)
            total_lines_added += sig.get('lines_added', 0)
            total_lines_removed += sig.get('lines_removed', 0)

        return {
            'total_signatures': len(signatures),
            'vuln_type_distribution': dict(vuln_type_counts),
            'avg_files_changed': total_files_changed / len(signatures) if signatures else 0,
            'avg_lines_added': total_lines_added / len(signatures) if signatures else 0,
            'avg_lines_removed': total_lines_removed / len(signatures) if signatures else 0,
        }
