"""
Unified Diff Parser - properly parses unified diffs and reconstructs full file contents.

This module handles the parsing of unified diff format and reconstructs
complete before/after file contents that can be properly parsed into ASTs.
"""

import re
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass


@dataclass
class DiffHunk:
    """Represents a single hunk in a unified diff."""
    old_start: int  # Starting line number in old file
    old_count: int  # Number of lines in old file
    new_start: int  # Starting line number in new file
    new_count: int  # Number of lines in new file
    lines: List[Tuple[str, str]]  # List of (prefix, content) tuples
    # prefix is: ' ' (context), '-' (removed), '+' (added)


@dataclass
class FileDiff:
    """Represents changes to a single file."""
    old_path: str
    new_path: str
    hunks: List[DiffHunk]
    is_new_file: bool = False
    is_deleted_file: bool = False


class UnifiedDiffParser:
    """
    Parser for unified diff format that reconstructs full file contents.

    This parser properly handles unified diffs and can reconstruct the complete
    before and after versions of files, which is essential for generating valid
    ASTs.
    """

    def __init__(self):
        """Initialize the parser."""
        # Regex patterns for parsing diff format
        self.file_header_pattern = re.compile(r'^---\s+(.+?)(?:\s+.*)?$')
        self.new_file_pattern = re.compile(r'^\+\+\+\s+(.+?)(?:\s+.*)?$')
        self.hunk_header_pattern = re.compile(
            r'^@@\s+-(\d+)(?:,(\d+))?\s+\+(\d+)(?:,(\d+))?\s+@@.*$'
        )

    def parse(self, diff_text: str) -> List[FileDiff]:
        """
        Parse a unified diff into structured FileDiff objects.

        Args:
            diff_text: Unified diff as string

        Returns:
            List of FileDiff objects, one per file changed
        """
        file_diffs = []
        current_file = None
        current_hunk = None

        lines = diff_text.split('\n')
        i = 0

        while i < len(lines):
            line = lines[i]

            # Check for file header (--- old_file)
            file_match = self.file_header_pattern.match(line)
            if file_match:
                # Save previous file if exists
                if current_file and current_file.hunks:
                    file_diffs.append(current_file)

                old_path = file_match.group(1)

                # Next line should be +++ new_file
                i += 1
                if i < len(lines):
                    new_match = self.new_file_pattern.match(lines[i])
                    if new_match:
                        new_path = new_match.group(1)
                        current_file = FileDiff(
                            old_path=old_path,
                            new_path=new_path,
                            hunks=[],
                            is_new_file=(old_path == '/dev/null'),
                            is_deleted_file=(new_path == '/dev/null')
                        )

                i += 1
                continue

            # Check for hunk header (@@ -old_start,old_count +new_start,new_count @@)
            hunk_match = self.hunk_header_pattern.match(line)
            if hunk_match and current_file:
                # Save previous hunk if exists
                if current_hunk:
                    current_file.hunks.append(current_hunk)

                old_start = int(hunk_match.group(1))
                old_count = int(hunk_match.group(2)) if hunk_match.group(2) else 1
                new_start = int(hunk_match.group(3))
                new_count = int(hunk_match.group(4)) if hunk_match.group(4) else 1

                current_hunk = DiffHunk(
                    old_start=old_start,
                    old_count=old_count,
                    new_start=new_start,
                    new_count=new_count,
                    lines=[]
                )

                i += 1
                continue

            # Parse hunk content lines
            if current_hunk is not None and line:
                if line[0] in (' ', '-', '+', '\\'):
                    if line[0] == '\\':
                        # "\ No newline at end of file" - skip
                        pass
                    else:
                        prefix = line[0]
                        content = line[1:] if len(line) > 1 else ''
                        current_hunk.lines.append((prefix, content))

            i += 1

        # Save last hunk and file
        if current_hunk and current_file:
            current_file.hunks.append(current_hunk)
        if current_file and current_file.hunks:
            file_diffs.append(current_file)

        return file_diffs

    def reconstruct_file(
        self,
        hunks: List[DiffHunk],
        version: str = 'old'
    ) -> Tuple[str, List[Tuple[int, int]]]:
        """
        Reconstruct a complete file from diff hunks.

        Args:
            hunks: List of hunks for a file
            version: 'old' for before version, 'new' for after version

        Returns:
            Tuple of (file_content, changed_line_ranges)
            where changed_line_ranges is a list of (start_line, end_line) tuples
        """
        if not hunks:
            return ('', [])

        # Determine which lines to include based on version
        if version == 'old':
            include_prefixes = {' ', '-'}  # Context and removed lines
            exclude_prefix = '+'
        else:  # version == 'new'
            include_prefixes = {' ', '+'}  # Context and added lines
            exclude_prefix = '-'

        # Track changed line ranges (1-indexed)
        changed_ranges = []

        # Reconstruct file line by line
        lines = []
        current_line = 0

        for hunk in hunks:
            start_line = hunk.old_start if version == 'old' else hunk.new_start

            # Track if we're in a changed section
            change_start = None

            for prefix, content in hunk.lines:
                if prefix in include_prefixes:
                    current_line += 1
                    lines.append(content)

                    # Track changed ranges
                    if prefix != ' ':  # Not context line
                        if change_start is None:
                            change_start = current_line
                    else:
                        if change_start is not None:
                            changed_ranges.append((change_start, current_line - 1))
                            change_start = None

            # Close any open changed range
            if change_start is not None:
                changed_ranges.append((change_start, current_line))

        file_content = '\n'.join(lines)
        return file_content, changed_ranges

    def make_php_parseable(self, code: str, file_path: str = '') -> str:
        """
        Ensure code is parseable as PHP by adding necessary wrappers.

        Args:
            code: PHP code (possibly incomplete)
            file_path: Path to the file (helps determine context)

        Returns:
            Code that can be parsed as valid PHP
        """
        if not code.strip():
            return '<?php\n'

        # Check if code already has PHP opening tag
        has_php_tag = '<?php' in code or '<?' in code

        # If no PHP tag and it looks like PHP code, add one
        if not has_php_tag:
            # Check if it looks like PHP code
            php_indicators = [
                'function ', 'class ', '$', 'public ', 'private ', 'protected ',
                'if (', 'while (', 'foreach (', 'echo ', 'return ', ';'
            ]

            if any(indicator in code for indicator in php_indicators):
                code = f"<?php\n{code}"

        return code

    def extract_php_files(self, file_diffs: List[FileDiff]) -> List[FileDiff]:
        """
        Filter to only PHP files from a list of file diffs.

        Args:
            file_diffs: List of all file diffs

        Returns:
            List of only PHP file diffs
        """
        php_extensions = {'.php', '.php3', '.php4', '.php5', '.phtml', '.inc'}

        php_files = []
        for file_diff in file_diffs:
            # Check file extension
            path = file_diff.new_path if file_diff.new_path != '/dev/null' else file_diff.old_path

            if any(path.endswith(ext) for ext in php_extensions):
                php_files.append(file_diff)

        return php_files

    def get_changed_line_ranges_unified(
        self,
        hunks: List[DiffHunk],
        version: str = 'old'
    ) -> List[Tuple[int, int]]:
        """
        Get line ranges that changed in a file (without reconstructing full file).

        Args:
            hunks: List of diff hunks
            version: 'old' or 'new'

        Returns:
            List of (start_line, end_line) tuples for changed regions
        """
        ranges = []

        for hunk in hunks:
            if version == 'old':
                start = hunk.old_start
            else:
                start = hunk.new_start

            current_line = start
            range_start = None

            for prefix, content in hunk.lines:
                is_context = prefix == ' '
                is_relevant = (version == 'old' and prefix == '-') or \
                             (version == 'new' and prefix == '+')

                if is_relevant:
                    if range_start is None:
                        range_start = current_line

                if is_context or is_relevant:
                    current_line += 1

                # Close range if we hit context after changes
                if is_context and range_start is not None:
                    ranges.append((range_start, current_line - 1))
                    range_start = None

            # Close any open range
            if range_start is not None:
                ranges.append((range_start, current_line - 1))

        # Merge overlapping ranges
        if ranges:
            ranges.sort()
            merged = [ranges[0]]
            for start, end in ranges[1:]:
                last_start, last_end = merged[-1]
                if start <= last_end + 1:
                    # Overlapping or adjacent, merge
                    merged[-1] = (last_start, max(end, last_end))
                else:
                    merged.append((start, end))
            ranges = merged

        return ranges
