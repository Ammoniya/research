"""
Improved AST Signature Generator - uses proper diff parsing and line mapping.

This module implements the correct approach:
1. Parse unified diff to get file paths and changed line ranges
2. Reconstruct full before/after files (valid PHP)
3. Parse with tree-sitter into ASTs
4. Use line ranges to locate changed AST nodes
5. Extract minimal differing subtree
6. Normalize to create reusable patterns
"""

from typing import Optional, List, Dict, Tuple
from pathlib import Path

from wordpress_vulnerability_analyzer.models import ASTNode
from wordpress_vulnerability_analyzer.ast_parser import PHPASTParser
from wordpress_vulnerability_analyzer.unified_diff_parser import UnifiedDiffParser, FileDiff
from wordpress_vulnerability_analyzer.ast_line_mapper import ASTLineMapper
from wordpress_vulnerability_analyzer.ast_normalizer import ASTNormalizer


class ImprovedSignatureGenerator:
    """
    Generates high-quality AST signatures using proper diff parsing.

    This generator follows the correct approach:
    - Parses full valid PHP files (not snippets)
    - Maps line ranges from diffs to AST nodes
    - Extracts minimal differing subtrees
    - Normalizes patterns for reusability
    """

    def __init__(self, verbose: bool = False):
        """
        Initialize the generator.

        Args:
            verbose: Print detailed progress
        """
        self.verbose = verbose
        self.diff_parser = UnifiedDiffParser()
        self.ast_parser = PHPASTParser()
        self.line_mapper = ASTLineMapper()
        self.normalizer = ASTNormalizer(
            normalize_vars=True,
            normalize_strings=False,  # Keep strings for XSS context
            normalize_function_names=False  # Keep function names for security analysis
        )

    def generate_from_unified_diff(
        self,
        unified_diff: str,
        cve: Optional[str] = None,
        plugin_slug: str = '',
        vuln_type: str = '',
        title: str = ''
    ) -> List[Dict]:
        """
        Generate AST signatures from a unified diff.

        Args:
            unified_diff: Unified diff string
            cve: CVE identifier
            plugin_slug: Plugin name
            vuln_type: Vulnerability type
            title: Vulnerability title

        Returns:
            List of signature dictionaries (one per file changed)
        """
        if self.verbose:
            print(f"\nProcessing unified diff for {cve or 'unknown CVE'}")

        # Step 1: Parse the unified diff
        file_diffs = self.diff_parser.parse(unified_diff)

        if self.verbose:
            print(f"  Found {len(file_diffs)} file(s) in diff")

        # Step 2: Filter to only PHP files
        php_files = self.diff_parser.extract_php_files(file_diffs)

        if self.verbose:
            print(f"  {len(php_files)} PHP file(s)")

        signatures = []

        # Step 3: Process each file
        for file_diff in php_files:
            file_sig = self._process_file_diff(
                file_diff,
                cve=cve,
                plugin_slug=plugin_slug,
                vuln_type=vuln_type,
                title=title
            )

            if file_sig:
                signatures.append(file_sig)

        return signatures

    def _process_file_diff(
        self,
        file_diff: FileDiff,
        cve: Optional[str],
        plugin_slug: str,
        vuln_type: str,
        title: str
    ) -> Optional[Dict]:
        """
        Process a single file diff to generate a signature.

        Args:
            file_diff: FileDiff object
            cve: CVE identifier
            plugin_slug: Plugin name
            vuln_type: Vulnerability type
            title: Vulnerability title

        Returns:
            Signature dictionary or None if processing fails
        """
        file_path = file_diff.new_path

        if self.verbose:
            print(f"\n  Processing: {file_path}")

        # Step 1: Reconstruct full before/after files
        vuln_code, vuln_ranges = self.diff_parser.reconstruct_file(
            file_diff.hunks,
            version='old'
        )
        patch_code, patch_ranges = self.diff_parser.reconstruct_file(
            file_diff.hunks,
            version='new'
        )

        if self.verbose:
            print(f"    Vulnerable version: {len(vuln_code)} bytes, {len(vuln_ranges)} changed range(s)")
            print(f"    Patched version: {len(patch_code)} bytes, {len(patch_ranges)} changed range(s)")

        # Step 2: Make code parseable (add PHP tags if needed)
        vuln_code = self.diff_parser.make_php_parseable(vuln_code, file_path)
        patch_code = self.diff_parser.make_php_parseable(patch_code, file_path)

        # Step 3: Parse into ASTs
        if self.verbose:
            print(f"    Parsing vulnerable version...")

        vuln_ast = self.ast_parser.parse(vuln_code)
        if not vuln_ast:
            if self.verbose:
                print(f"    ✗ Failed to parse vulnerable code")
            return None

        if self.verbose:
            print(f"    Parsing patched version...")

        patch_ast = self.ast_parser.parse(patch_code)
        if not patch_ast:
            if self.verbose:
                print(f"    ✗ Failed to parse patched code")
            return None

        # Step 4: Find ALL nodes in changed line ranges (not just minimal)
        if self.verbose:
            print(f"    Finding nodes in changed ranges...")

        vuln_nodes = []
        patch_nodes = []

        for start, end in vuln_ranges:
            vuln_nodes.extend(self.line_mapper.find_nodes_in_range(vuln_ast, start, end))

        for start, end in patch_ranges:
            patch_nodes.extend(self.line_mapper.find_nodes_in_range(patch_ast, start, end))

        if not vuln_nodes:
            if self.verbose:
                print(f"    ✗ No vulnerable nodes found in changed ranges")
            return None

        if self.verbose:
            print(f"    Found {len(vuln_nodes)} total node(s) in vulnerable version")

        # Step 5: Find the most meaningful differing pair
        # Filter to meaningful node types first
        meaningful_vuln = self._filter_to_meaningful_nodes(vuln_nodes)
        meaningful_patch = self._filter_to_meaningful_nodes(patch_nodes)

        if self.verbose and meaningful_vuln:
            print(f"    Filtered to {len(meaningful_vuln)} meaningful vulnerable node(s)")

        if not meaningful_vuln:
            # Fall back to all nodes if no meaningful ones
            meaningful_vuln = vuln_nodes

        smallest_pair = self._find_smallest_differing_pair(
            meaningful_vuln,
            meaningful_patch if meaningful_patch else patch_nodes
        )

        if not smallest_pair:
            if self.verbose:
                print(f"    ✗ Could not find differing node pair")
            return None

        vuln_node, patch_node = smallest_pair

        if self.verbose:
            print(f"    Minimal diff: {vuln_node.node_type} (lines {vuln_node.start_point[0]+1}-{vuln_node.end_point[0]+1})")

        # Step 6: Normalize to create patterns
        if self.verbose:
            print(f"    Normalizing patterns...")

        pattern_signature = self.normalizer.create_pattern_signature(vuln_node, patch_node)

        # Step 7: Compare security functions
        security_diff = self.normalizer.compare_security_functions(vuln_node, patch_node)

        # Step 8: Create complete signature
        signature = {
            'cve': cve,
            'plugin_slug': plugin_slug,
            'vuln_type': vuln_type,
            'title': title,
            'file_path': file_path,

            # Pattern information
            'vulnerable_pattern': pattern_signature['vulnerable_pattern'],
            'patched_pattern': pattern_signature.get('patched_pattern'),
            'pattern_type': pattern_signature['pattern_type'],

            # Security function analysis
            'security_functions_added': list(security_diff['added']),
            'security_functions_removed': list(security_diff['removed']),

            # Code snippets (for reference)
            'vulnerable_code_snippet': vuln_node.text[:500],
            'patched_code_snippet': patch_node.text[:500] if patch_node else '',

            # Metadata
            'constraints': {
                'file_extension': Path(file_path).suffix,
                'node_type': vuln_node.node_type,
                'changed_lines': vuln_ranges,
            }
        }

        # Create detection rule
        detection_rule = self.normalizer.create_detection_rule(
            pattern_signature['vulnerable_pattern'],
            metadata={
                'cve': cve,
                'type': vuln_type,
                'severity': self._infer_severity(vuln_type, security_diff)
            }
        )

        signature['detection_rule'] = detection_rule

        if self.verbose:
            print(f"    ✓ Signature generated successfully")
            print(f"      Pattern type: {pattern_signature['pattern_type']}")
            if security_diff['added']:
                print(f"      Security functions added: {', '.join(security_diff['added'])}")

        return signature

    def _find_smallest_differing_pair(
        self,
        vuln_nodes: List[ASTNode],
        patch_nodes: List[ASTNode]
    ) -> Optional[Tuple[ASTNode, ASTNode]]:
        """
        Find the smallest pair of nodes that differ.

        Args:
            vuln_nodes: Nodes from vulnerable version
            patch_nodes: Nodes from patched version

        Returns:
            Tuple of (vuln_node, patch_node) or None
        """
        if not vuln_nodes or not patch_nodes:
            return None

        # Find the smallest vulnerable node
        smallest_vuln = min(vuln_nodes, key=lambda n: n.end_byte - n.start_byte)

        # Find corresponding patch node (by position/type)
        # Simple heuristic: find patch node with same type and close position
        best_patch = None
        best_score = float('inf')

        vuln_line = smallest_vuln.start_point[0]

        for patch_node in patch_nodes:
            # Score based on line distance and type match
            line_dist = abs(patch_node.start_point[0] - vuln_line)
            type_match = 0 if patch_node.node_type == smallest_vuln.node_type else 10

            score = line_dist + type_match

            if score < best_score:
                best_score = score
                best_patch = patch_node

        if best_patch:
            return (smallest_vuln, best_patch)

        # If no good match, just pair with first patch node
        return (smallest_vuln, patch_nodes[0])

    def _filter_to_meaningful_nodes(self, nodes: List[ASTNode]) -> List[ASTNode]:
        """
        Filter nodes to only meaningful types for vulnerability signatures.

        We want statement-level or expression-level nodes, not tiny tokens.

        Args:
            nodes: List of AST nodes

        Returns:
            Filtered list of meaningful nodes
        """
        # Meaningful node types for vulnerability detection
        # Prioritize larger constructs (statements) over smaller ones (expressions)
        meaningful_types = {
            # Statements (highest priority)
            'expression_statement', 'echo_statement', 'return_statement',
            'if_statement', 'while_statement', 'for_statement', 'foreach_statement',

            # Expressions (medium priority)
            'assignment_expression', 'function_call_expression',
            'binary_expression', 'concatenation', 'string_concatenation',
            'member_call_expression', 'scoped_call_expression',

            # Function/method calls
            'function_call', 'method_call', 'scoped_call',

            # Declarations
            'function_definition', 'method_declaration', 'class_declaration',

            # SQL/DB operations
            'prepare', 'query',
        }

        # Exclude these tiny tokens even if they match
        exclude_types = {'echo', 'if', 'return', 'for', 'while', '(', ')', '{', '}', ';', ',', '.', '+', '-', '*', '/'}

        meaningful = []
        for node in nodes:
            # Skip tiny tokens
            if node.node_type in exclude_types:
                continue

            if node.node_type in meaningful_types:
                meaningful.append(node)
            # Also include nodes with interesting text (security functions)
            elif node.text and len(node.text) > 10 and any(func in node.text.lower() for func in [
                'esc_', 'sanitize_', 'wp_kses', 'prepare', '$_'
            ]):
                meaningful.append(node)

        return meaningful

    def _infer_severity(self, vuln_type: str, security_diff: Dict) -> str:
        """
        Infer vulnerability severity.

        Args:
            vuln_type: Vulnerability type string
            security_diff: Security functions diff

        Returns:
            Severity string: 'critical', 'high', 'medium', 'low'
        """
        vuln_lower = vuln_type.lower()

        # Critical: RCE, Auth bypass, SQL injection
        if any(x in vuln_lower for x in ['rce', 'remote code', 'sql injection', 'auth bypass']):
            return 'critical'

        # High: XSS, deserialization, file upload
        if any(x in vuln_lower for x in ['xss', 'cross-site', 'unserialize', 'file upload']):
            return 'high'

        # Medium: CSRF, info disclosure
        if any(x in vuln_lower for x in ['csrf', 'information disclosure', 'path traversal']):
            return 'medium'

        # Default
        return 'medium'

    def generate_from_code_snippets(
        self,
        vuln_code: str,
        patch_code: str,
        cve: Optional[str] = None,
        plugin_slug: str = '',
        vuln_type: str = '',
        title: str = '',
        file_path: str = ''
    ) -> Optional[Dict]:
        """
        Generate signature from code snippets (fallback when no diff available).

        Args:
            vuln_code: Vulnerable code
            patch_code: Patched code
            cve: CVE identifier
            plugin_slug: Plugin name
            vuln_type: Vulnerability type
            title: Vulnerability title
            file_path: File path

        Returns:
            Signature dictionary or None
        """
        if self.verbose:
            print(f"\nGenerating signature from code snippets for {cve or 'unknown CVE'}")

        # Make code parseable
        vuln_code = self.diff_parser.make_php_parseable(vuln_code, file_path)
        patch_code = self.diff_parser.make_php_parseable(patch_code, file_path)

        # Parse
        vuln_ast = self.ast_parser.parse(vuln_code)
        patch_ast = self.ast_parser.parse(patch_code)

        if not vuln_ast or not patch_ast:
            if self.verbose:
                print("  ✗ Failed to parse code")
            return None

        # For snippets, we can't use line ranges, so just normalize the whole AST
        pattern_signature = self.normalizer.create_pattern_signature(vuln_ast, patch_ast)
        security_diff = self.normalizer.compare_security_functions(vuln_ast, patch_ast)

        signature = {
            'cve': cve,
            'plugin_slug': plugin_slug,
            'vuln_type': vuln_type,
            'title': title,
            'file_path': file_path,
            'vulnerable_pattern': pattern_signature['vulnerable_pattern'],
            'patched_pattern': pattern_signature.get('patched_pattern'),
            'pattern_type': pattern_signature['pattern_type'],
            'security_functions_added': list(security_diff['added']),
            'security_functions_removed': list(security_diff['removed']),
            'constraints': {
                'file_extension': Path(file_path).suffix if file_path else '.php',
            }
        }

        if self.verbose:
            print(f"  ✓ Signature generated from snippets")

        return signature
