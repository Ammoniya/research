"""Research metrics calculator for vulnerability patterns."""

import json
import os
from typing import List, Dict
from datetime import datetime
from collections import defaultdict

from .models import (
    PluginTimeline,
    VulnerabilityClone,
    ResearchMetrics,
    FixStatus
)


class MetricsCalculator:
    """Calculates research metrics for vulnerability patterns."""

    def __init__(self, output_dir: str):
        """
        Initialize metrics calculator.

        Args:
            output_dir: Directory for metrics outputs
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def calculate_vpp(
        self,
        signature_id: str,
        total_plugins_scanned: int,
        timelines: List[PluginTimeline]
    ) -> float:
        """
        Calculate Vulnerability Pattern Prevalence (VPP).

        VPP = (Plugins with pattern) / (Total plugins scanned) × 100

        Args:
            signature_id: Signature ID
            total_plugins_scanned: Total plugins scanned
            timelines: Timelines for this pattern

        Returns:
            float: VPP percentage
        """
        unique_plugins = set(t.plugin_slug for t in timelines)
        plugins_with_pattern = len(unique_plugins)

        if total_plugins_scanned == 0:
            return 0.0

        vpp = (plugins_with_pattern / total_plugins_scanned) * 100
        return round(vpp, 4)

    def calculate_ppd(
        self,
        timelines: List[PluginTimeline]
    ) -> float:
        """
        Calculate Pattern Persistence Duration (PPD).

        PPD = Average(Date_fixed - Date_introduced) for each instance

        Args:
            timelines: Timelines for this pattern

        Returns:
            float: Average persistence in days
        """
        persistence_days = [
            t.persistence_days for t in timelines
            if t.persistence_days > 0
        ]

        if not persistence_days:
            return 0.0

        ppd = sum(persistence_days) / len(persistence_days)
        return round(ppd, 2)

    def calculate_sfr(
        self,
        timelines: List[PluginTimeline]
    ) -> float:
        """
        Calculate Silent Fix Rate (SFR).

        SFR = (Patterns fixed without CVE) / (Total fixed patterns) × 100

        Args:
            timelines: Timelines for this pattern

        Returns:
            float: SFR percentage
        """
        total_fixes = sum(
            1 for t in timelines
            if t.fix_status in [FixStatus.FIXED_WITH_CVE, FixStatus.FIXED_SILENTLY]
        )

        silent_fixes = sum(
            1 for t in timelines
            if t.fix_status == FixStatus.FIXED_SILENTLY
        )

        if total_fixes == 0:
            return 0.0

        sfr = (silent_fixes / total_fixes) * 100
        return round(sfr, 2)

    def calculate_ew(
        self,
        timelines: List[PluginTimeline]
    ) -> int:
        """
        Calculate Exploitability Window (EW).

        EW = Sum of days each vulnerable pattern existed across all plugins

        Args:
            timelines: Timelines for this pattern

        Returns:
            int: Total days of exposure
        """
        total_days = sum(t.persistence_days for t in timelines)
        return total_days

    def calculate_all_metrics(
        self,
        signature_id: str,
        vulnerability_type: str,
        total_plugins_scanned: int,
        timelines: List[PluginTimeline]
    ) -> ResearchMetrics:
        """
        Calculate all research metrics for a pattern.

        Args:
            signature_id: Signature ID
            vulnerability_type: Type of vulnerability
            total_plugins_scanned: Total plugins scanned
            timelines: Timelines for this pattern

        Returns:
            ResearchMetrics: All calculated metrics
        """
        metrics = ResearchMetrics(
            signature_id=signature_id,
            vulnerability_type=vulnerability_type,
            total_plugins_scanned=total_plugins_scanned
        )

        # Calculate core metrics
        metrics.vpp = self.calculate_vpp(signature_id, total_plugins_scanned, timelines)
        metrics.ppd = self.calculate_ppd(timelines)
        metrics.sfr = self.calculate_sfr(timelines)
        metrics.ew = self.calculate_ew(timelines)

        # Supporting data
        metrics.plugins_with_pattern = len(set(t.plugin_slug for t in timelines))

        metrics.total_fixes = sum(
            1 for t in timelines
            if t.fix_status in [FixStatus.FIXED_WITH_CVE, FixStatus.FIXED_SILENTLY]
        )

        metrics.silent_fixes = sum(
            1 for t in timelines
            if t.fix_status == FixStatus.FIXED_SILENTLY
        )

        # Temporal data
        appearances = [
            t.first_appearance for t in timelines
            if t.first_appearance
        ]

        if appearances:
            metrics.earliest_appearance = min(appearances)
            metrics.latest_appearance = max(appearances)
            metrics.calculate_pattern_lifespan()

        return metrics

    def calculate_ecosystem_metrics(
        self,
        all_clones: List[VulnerabilityClone],
        total_plugins_scanned: int
    ) -> Dict:
        """
        Calculate ecosystem-wide metrics.

        Args:
            all_clones: All vulnerability clones
            total_plugins_scanned: Total plugins scanned

        Returns:
            Dict: Ecosystem metrics
        """
        # Aggregate all timelines
        all_timelines = []
        for clone in all_clones:
            all_timelines.extend(clone.timelines)

        # Calculate aggregate metrics
        total_vulnerable_plugins = len(set(t.plugin_slug for t in all_timelines))
        total_still_vulnerable = sum(1 for t in all_timelines if t.currently_vulnerable)

        # Vulnerability type distribution
        vuln_type_counts = defaultdict(int)
        for clone in all_clones:
            vuln_type_counts[clone.vulnerability_type] += clone.total_clones

        # Average metrics across all patterns
        avg_vpp = sum(
            len(set(t.plugin_slug for t in clone.timelines)) / total_plugins_scanned * 100
            for clone in all_clones if clone.timelines
        ) / len(all_clones) if all_clones else 0

        avg_ppd = sum(clone.avg_persistence_days for clone in all_clones) / len(all_clones) if all_clones else 0

        total_ew = sum(
            sum(t.persistence_days for t in clone.timelines)
            for clone in all_clones
        )

        # Silent fix analysis
        total_fixes = sum(
            1 for t in all_timelines
            if t.fix_status in [FixStatus.FIXED_WITH_CVE, FixStatus.FIXED_SILENTLY]
        )

        silent_fixes = sum(
            1 for t in all_timelines
            if t.fix_status == FixStatus.FIXED_SILENTLY
        )

        ecosystem_sfr = (silent_fixes / total_fixes * 100) if total_fixes > 0 else 0

        # Top vulnerable patterns
        top_patterns = sorted(
            all_clones,
            key=lambda c: c.total_clones,
            reverse=True
        )[:10]

        return {
            'ecosystem_summary': {
                'total_plugins_scanned': total_plugins_scanned,
                'total_vulnerable_plugins': total_vulnerable_plugins,
                'total_still_vulnerable': total_still_vulnerable,
                'total_patterns_tracked': len(all_clones),
                'total_clones_found': sum(c.total_clones for c in all_clones),
            },
            'aggregate_metrics': {
                'avg_vpp': round(avg_vpp, 4),
                'avg_ppd': round(avg_ppd, 2),
                'ecosystem_sfr': round(ecosystem_sfr, 2),
                'total_ew': total_ew,
            },
            'vulnerability_type_distribution': dict(vuln_type_counts),
            'top_patterns': [
                {
                    'signature_id': p.signature_id,
                    'vulnerability_type': p.vulnerability_type,
                    'total_clones': p.total_clones,
                    'still_vulnerable': p.still_vulnerable_count,
                    'avg_persistence_days': round(p.avg_persistence_days, 2),
                }
                for p in top_patterns
            ],
            'fix_analysis': {
                'total_fixes': total_fixes,
                'cve_fixes': total_fixes - silent_fixes,
                'silent_fixes': silent_fixes,
                'silent_fix_rate': round(ecosystem_sfr, 2),
            }
        }

    def save_metrics(self, metrics: ResearchMetrics):
        """
        Save metrics to file.

        Args:
            metrics: Metrics to save
        """
        filename = f"metrics_{metrics.signature_id}.json"
        filepath = os.path.join(self.output_dir, filename)

        with open(filepath, 'w') as f:
            json.dump(metrics.to_dict(), f, indent=2)

    def save_ecosystem_metrics(self, ecosystem_metrics: Dict):
        """
        Save ecosystem metrics to file.

        Args:
            ecosystem_metrics: Ecosystem metrics dictionary
        """
        filepath = os.path.join(self.output_dir, "ecosystem_metrics.json")

        with open(filepath, 'w') as f:
            json.dump(ecosystem_metrics, f, indent=2)

    def generate_metrics_report(
        self,
        all_clones: List[VulnerabilityClone],
        total_plugins_scanned: int
    ) -> str:
        """
        Generate human-readable metrics report.

        Args:
            all_clones: All vulnerability clones
            total_plugins_scanned: Total plugins scanned

        Returns:
            str: Formatted report
        """
        ecosystem_metrics = self.calculate_ecosystem_metrics(
            all_clones,
            total_plugins_scanned
        )

        report = []
        report.append("=" * 80)
        report.append("WORDPRESS VULNERABILITY PATTERN RESEARCH METRICS")
        report.append("=" * 80)
        report.append("")

        # Ecosystem Summary
        summary = ecosystem_metrics['ecosystem_summary']
        report.append("ECOSYSTEM SUMMARY")
        report.append("-" * 80)
        report.append(f"Total Plugins Scanned:        {summary['total_plugins_scanned']:,}")
        report.append(f"Plugins with Vulnerabilities: {summary['total_vulnerable_plugins']:,}")
        report.append(f"Still Vulnerable:             {summary['total_still_vulnerable']:,}")
        report.append(f"Patterns Tracked:             {summary['total_patterns_tracked']:,}")
        report.append(f"Total Clones Found:           {summary['total_clones_found']:,}")
        report.append("")

        # Aggregate Metrics
        agg = ecosystem_metrics['aggregate_metrics']
        report.append("AGGREGATE RESEARCH METRICS")
        report.append("-" * 80)
        report.append(f"Average VPP (Prevalence):     {agg['avg_vpp']:.4f}%")
        report.append(f"Average PPD (Persistence):    {agg['avg_ppd']:.2f} days")
        report.append(f"Ecosystem SFR (Silent Fixes): {agg['ecosystem_sfr']:.2f}%")
        report.append(f"Total EW (Exposure Window):   {agg['total_ew']:,} days")
        report.append("")

        # Fix Analysis
        fix = ecosystem_metrics['fix_analysis']
        report.append("FIX ANALYSIS")
        report.append("-" * 80)
        report.append(f"Total Fixes:                  {fix['total_fixes']:,}")
        report.append(f"Fixes with CVE:               {fix['cve_fixes']:,}")
        report.append(f"Silent Fixes (no CVE):        {fix['silent_fixes']:,}")
        report.append(f"Silent Fix Rate:              {fix['silent_fix_rate']:.2f}%")
        report.append("")

        # Top Patterns
        report.append("TOP 10 MOST PREVALENT PATTERNS")
        report.append("-" * 80)
        for i, pattern in enumerate(ecosystem_metrics['top_patterns'], 1):
            report.append(f"{i}. {pattern['signature_id']}")
            report.append(f"   Type: {pattern['vulnerability_type']}")
            report.append(f"   Clones: {pattern['total_clones']}, Still Vulnerable: {pattern['still_vulnerable']}")
            report.append(f"   Avg Persistence: {pattern['avg_persistence_days']} days")
            report.append("")

        # Vulnerability Type Distribution
        report.append("VULNERABILITY TYPE DISTRIBUTION")
        report.append("-" * 80)
        vuln_dist = ecosystem_metrics['vulnerability_type_distribution']
        for vuln_type, count in sorted(vuln_dist.items(), key=lambda x: x[1], reverse=True)[:10]:
            report.append(f"{vuln_type:50s} {count:>5,}")

        report.append("")
        report.append("=" * 80)

        return "\n".join(report)
