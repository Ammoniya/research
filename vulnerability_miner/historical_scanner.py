"""Historical scanner for plugin SVN repositories."""

import os
import subprocess
import json
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from pathlib import Path
import re


class HistoricalScanner:
    """Scans WordPress plugin SVN histories for vulnerability patterns."""

    def __init__(
        self,
        svn_repos_dir: str,
        cache_dir: Optional[str] = None,
        svn_log_timeout: int = 300,
        svn_cat_timeout: int = 120,
        svn_list_timeout: int = 120
    ):
        """
        Initialize historical scanner.

        Args:
            svn_repos_dir: Directory containing SVN repositories
            cache_dir: Optional cache directory for performance
            svn_log_timeout: Timeout for svn log operations (seconds)
            svn_cat_timeout: Timeout for svn cat operations (seconds)
            svn_list_timeout: Timeout for svn list operations (seconds)
        """
        self.svn_repos_dir = svn_repos_dir
        self.cache_dir = cache_dir
        self.svn_log_timeout = svn_log_timeout
        self.svn_cat_timeout = svn_cat_timeout
        self.svn_list_timeout = svn_list_timeout

    def get_plugin_path(self, plugin_slug: str) -> Optional[str]:
        """
        Get path to plugin SVN repository.

        Args:
            plugin_slug: Plugin slug

        Returns:
            Optional[str]: Path to plugin directory or None
        """
        plugin_path = os.path.join(self.svn_repos_dir, plugin_slug)
        if os.path.exists(plugin_path):
            return plugin_path
        return None

    def get_all_revisions(self, plugin_slug: str, max_revisions: Optional[int] = None) -> List[Dict]:
        """
        Get all SVN revisions for a plugin.

        Args:
            plugin_slug: Plugin slug
            max_revisions: Optional limit on number of revisions

        Returns:
            List[Dict]: List of revision info dicts
        """
        # Check cache first
        if self.cache_dir:
            cache_file = os.path.join(self.cache_dir, f"{plugin_slug}_revisions.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r') as f:
                    cached_data = json.load(f)
                    if max_revisions:
                        return cached_data[:max_revisions]
                    return cached_data

        plugin_path = self.get_plugin_path(plugin_slug)
        if not plugin_path:
            return []

        try:
            # Get SVN log
            result = subprocess.run(
                ['svn', 'log', '--xml', plugin_path],
                capture_output=True,
                text=True,
                timeout=self.svn_log_timeout
            )

            if result.returncode != 0:
                return []

            # Parse XML log (simple parsing)
            revisions = self._parse_svn_log_xml(result.stdout)

            # Cache the results
            if self.cache_dir and revisions:
                os.makedirs(self.cache_dir, exist_ok=True)
                cache_file = os.path.join(self.cache_dir, f"{plugin_slug}_revisions.json")
                with open(cache_file, 'w') as f:
                    json.dump(revisions, f)

            if max_revisions:
                return revisions[:max_revisions]

            return revisions

        except (subprocess.TimeoutExpired, Exception) as e:
            print(f"Error getting revisions for {plugin_slug}: {e}")
            return []

    def _parse_svn_log_xml(self, xml_output: str) -> List[Dict]:
        """
        Parse SVN log XML output.

        Args:
            xml_output: XML output from svn log

        Returns:
            List[Dict]: Parsed revision info
        """
        revisions = []

        # Simple regex-based parsing (for production, use xml.etree.ElementTree)
        revision_pattern = r'<logentry\s+revision="(\d+)">'
        date_pattern = r'<date>(.*?)</date>'
        msg_pattern = r'<msg>(.*?)</msg>'

        entries = xml_output.split('</logentry>')
        for entry in entries:
            rev_match = re.search(revision_pattern, entry)
            if not rev_match:
                continue

            revision = int(rev_match.group(1))
            date_match = re.search(date_pattern, entry, re.DOTALL)
            msg_match = re.search(msg_pattern, entry, re.DOTALL)

            date_str = date_match.group(1).strip() if date_match else ""
            message = msg_match.group(1).strip() if msg_match else ""

            # Parse date
            try:
                # SVN date format: 2019-07-01T10:00:00.000000Z
                revision_date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            except:
                revision_date = None

            revisions.append({
                'revision': revision,
                'date': revision_date.isoformat() if revision_date else None,
                'message': message
            })

        return sorted(revisions, key=lambda x: x['revision'], reverse=True)

    def get_file_content_at_revision(
        self,
        plugin_slug: str,
        file_path: str,
        revision: int
    ) -> Optional[str]:
        """
        Get file content at specific revision.

        Args:
            plugin_slug: Plugin slug
            file_path: File path relative to plugin root
            revision: SVN revision number

        Returns:
            Optional[str]: File content or None
        """
        plugin_path = self.get_plugin_path(plugin_slug)
        if not plugin_path:
            return None

        full_path = os.path.join(plugin_path, file_path)

        try:
            result = subprocess.run(
                ['svn', 'cat', '-r', str(revision), full_path],
                capture_output=True,
                text=True,
                timeout=self.svn_cat_timeout
            )

            if result.returncode == 0:
                return result.stdout

            return None

        except subprocess.TimeoutExpired:
            # Silent timeout - file content retrieval timed out
            return None
        except Exception:
            return None

    def get_all_php_files_at_revision(self, plugin_slug: str, revision: int) -> List[str]:
        """
        Get list of all PHP files at a specific revision.

        Args:
            plugin_slug: Plugin slug
            revision: SVN revision number

        Returns:
            List[str]: List of PHP file paths
        """
        plugin_path = self.get_plugin_path(plugin_slug)
        if not plugin_path:
            return []

        try:
            import sys
            # Show that we're listing files (this can be slow)
            print(f" listing files...", end='', flush=True)

            result = subprocess.run(
                ['svn', 'list', '-R', '-r', str(revision), plugin_path],
                capture_output=True,
                text=True,
                timeout=self.svn_list_timeout
            )

            if result.returncode != 0:
                print(f" ERROR", end='', flush=True)
                return []

            # Filter for PHP files
            all_files = result.stdout.strip().split('\n')
            php_files = [f for f in all_files if f.endswith('.php')]

            return php_files

        except subprocess.TimeoutExpired:
            print(f" TIMEOUT after {self.svn_list_timeout}s", end='', flush=True)
            return []
        except Exception as e:
            print(f" ERROR: {e}", end='', flush=True)
            return []

    def get_current_version(self, plugin_slug: str) -> Optional[str]:
        """
        Get current version of plugin.

        Args:
            plugin_slug: Plugin slug

        Returns:
            Optional[str]: Current version or None
        """
        plugin_path = self.get_plugin_path(plugin_slug)
        if not plugin_path:
            return None

        # Try to read version from trunk/readme.txt
        readme_path = os.path.join(plugin_path, 'trunk', 'readme.txt')
        if not os.path.exists(readme_path):
            return None

        try:
            with open(readme_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Look for "Stable tag: X.Y.Z"
            match = re.search(r'Stable tag:\s*([0-9.]+)', content, re.IGNORECASE)
            if match:
                return match.group(1)

        except Exception:
            pass

        return None

    def get_tags(self, plugin_slug: str) -> List[str]:
        """
        Get all version tags for a plugin.

        Args:
            plugin_slug: Plugin slug

        Returns:
            List[str]: List of version tags
        """
        plugin_path = self.get_plugin_path(plugin_slug)
        if not plugin_path:
            return []

        tags_path = os.path.join(plugin_path, 'tags')
        if not os.path.exists(tags_path):
            return []

        try:
            tags = os.listdir(tags_path)
            # Filter and sort version tags
            version_tags = [t for t in tags if re.match(r'^[0-9.]+', t)]
            return sorted(version_tags, key=lambda v: [int(x) for x in v.split('.') if x.isdigit()])

        except Exception:
            return []

    def scan_revision_for_pattern(
        self,
        plugin_slug: str,
        revision: int,
        pattern_detector,
        signature_pattern: str
    ) -> List[Dict]:
        """
        Scan a specific revision for a vulnerability pattern.

        Args:
            plugin_slug: Plugin slug
            revision: Revision number
            pattern_detector: PatternMatcher instance
            signature_pattern: Pattern to search for

        Returns:
            List[Dict]: List of matches found
        """
        matches = []

        # Get all PHP files at this revision
        php_files = self.get_all_php_files_at_revision(plugin_slug, revision)

        for file_path in php_files:
            # Get file content
            content = self.get_file_content_at_revision(plugin_slug, file_path, revision)
            if not content:
                continue

            # Check for pattern match
            file_matches = pattern_detector.find_pattern_in_code(
                content,
                signature_pattern,
                file_path
            )

            if file_matches:
                matches.extend(file_matches)

        return matches

    def estimate_total_revisions(self, plugin_slug: str) -> int:
        """
        Estimate total number of revisions for a plugin.

        Args:
            plugin_slug: Plugin slug

        Returns:
            int: Estimated revision count
        """
        revisions = self.get_all_revisions(plugin_slug, max_revisions=1)
        if revisions:
            return revisions[0]['revision']
        return 0

    def get_release_revisions(self, plugin_slug: str, max_releases: Optional[int] = None) -> List[Dict]:
        """
        Get SVN revisions for released versions (tags) only.

        This is much faster than scanning all commits and focuses on official releases.

        Args:
            plugin_slug: Plugin slug
            max_releases: Optional limit on number of releases

        Returns:
            List[Dict]: List of revision info dicts for releases
        """
        # Check cache first
        if self.cache_dir:
            cache_file = os.path.join(self.cache_dir, f"{plugin_slug}_release_revisions.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r') as f:
                    cached_data = json.load(f)
                    if max_releases:
                        return cached_data[:max_releases]
                    return cached_data

        plugin_path = self.get_plugin_path(plugin_slug)
        if not plugin_path:
            return []

        tags_path = os.path.join(plugin_path, 'tags')
        if not os.path.exists(tags_path):
            return []

        try:
            # Get all version tags
            tags = self.get_tags(plugin_slug)
            if not tags:
                return []

            release_revisions = []

            # Get the last changed revision for each tag
            for tag in tags:
                tag_path = os.path.join(tags_path, tag)

                try:
                    # Get SVN info for this tag to find its revision
                    result = subprocess.run(
                        ['svn', 'info', '--xml', tag_path],
                        capture_output=True,
                        text=True,
                        timeout=30
                    )

                    if result.returncode == 0:
                        # Parse revision from XML
                        rev_match = re.search(r'revision="(\d+)"', result.stdout)
                        date_match = re.search(r'<date>(.*?)</date>', result.stdout)

                        if rev_match:
                            revision = int(rev_match.group(1))
                            date_str = date_match.group(1).strip() if date_match else ""

                            # Parse date
                            try:
                                revision_date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                            except:
                                revision_date = None

                            release_revisions.append({
                                'revision': revision,
                                'date': revision_date.isoformat() if revision_date else None,
                                'message': f'Release {tag}',
                                'tag': tag
                            })

                except (subprocess.TimeoutExpired, Exception) as e:
                    # Skip this tag if we can't get its info
                    continue

            # Sort by revision number (newest first)
            release_revisions = sorted(release_revisions, key=lambda x: x['revision'], reverse=True)

            # Cache the results
            if self.cache_dir and release_revisions:
                os.makedirs(self.cache_dir, exist_ok=True)
                cache_file = os.path.join(self.cache_dir, f"{plugin_slug}_release_revisions.json")
                with open(cache_file, 'w') as f:
                    json.dump(release_revisions, f)

            if max_releases:
                return release_revisions[:max_releases]

            return release_revisions

        except Exception as e:
            print(f"Error getting release revisions for {plugin_slug}: {e}")
            return []
